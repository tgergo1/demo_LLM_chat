{
  "name": "Hello and Greeting",
  "pinned": false,
  "createdAt": 1753001423421,
  "preset": "",
  "tokenCount": 1049,
  "systemPrompt": "",
  "messages": [
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "Hello how are you"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "meta-llama-3.1-8b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1753378025441-0.4950554086370389",
              "content": [
                {
                  "type": "text",
                  "text": "I'm a large language model, so I don't have feelings or emotions like humans do. However, I'm functioning properly and ready to help you with any questions or tasks you may have. How can I assist you today?",
                  "fromDraftModel": false,
                  "tokensCount": 46
                }
              ],
              "genInfo": {
                "indexedModelIdentifier": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
                "identifier": "meta-llama-3.1-8b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.contextLength",
                      "value": 4096
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.toolCallStopStrings",
                      "value": [
                        "<|eom_id|>",
                        "<|eom|>"
                      ]
                    },
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- if messages[0]['content'] is string %}\n      {%- set first_user_message = messages[0]['content']|trim %}\n  {%- else %}\n      {#- expect messages[0]['content'] to be a list of objects #}\n      {%- set first_user_message = messages[0]['content'][0]['text']|trim %}\n  {%- endif %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"You are an expert in using functions/tools when necessary. You are given a query and a set of possible functions. \"}}\n    {{- \"Based on the query, call one or more functions to achieve the purpose, if applicable.\\n\\n\"}}\n    {{- \"If no functions apply, do not call any. Make sure to use any parameters specified as required. \"}}\n    {{- \"If the given query lacks the parameters required by the function, \"}}\n    {{- \"point it out. If a function response is given after you call a function, use it if it answers the query. \"}}\n    {{- \"You should only output function calls in tool call sections.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument names and their values}. ' }}\n    {{- \"For number argument values, you do not need to wrap in quotes. If you use quotes, use double quotes. \"}}\n    {{- \"Do not use variables. Here is a list of the only functions you can invoke, in JSON format.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is iterable and message.content is not string %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n"
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.topPSampling",
                      "value": {
                        "checked": false,
                        "value": 1
                      }
                    },
                    {
                      "key": "llm.prediction.minPSampling",
                      "value": {
                        "checked": false,
                        "value": 0
                      }
                    },
                    {
                      "key": "llm.prediction.repeatPenalty",
                      "value": {
                        "checked": true,
                        "value": 1.1
                      }
                    },
                    {
                      "key": "llm.prediction.topKSampling",
                      "value": 100
                    },
                    {
                      "key": "llm.prediction.tools",
                      "value": {
                        "type": "none"
                      }
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 78.29703939319795,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 1.071,
                  "promptTokensCount": 39,
                  "predictedTokensCount": 47,
                  "totalTokensCount": 86
                }
              },
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1753378025994-0.24097150704329395",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "So this is the second chat"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "meta-llama-3.1-8b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1753378522488-0.17289077054908564",
              "content": [
                {
                  "type": "text",
                  "text": "I'm glad we're continuing our conversation from earlier. Unfortunately, I'm a large language model, I don't have the ability to retain information or memories of previous chats. Each time you interact with me, it's a new conversation.\n\nHowever, I can still recall any information we discussed earlier if you'd like to pick up where we left off. What would you like to talk about now?",
                  "fromDraftModel": false,
                  "tokensCount": 80
                }
              ],
              "genInfo": {
                "indexedModelIdentifier": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
                "identifier": "meta-llama-3.1-8b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.contextLength",
                      "value": 4096
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.toolCallStopStrings",
                      "value": [
                        "<|eom_id|>",
                        "<|eom|>"
                      ]
                    },
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- if messages[0]['content'] is string %}\n      {%- set first_user_message = messages[0]['content']|trim %}\n  {%- else %}\n      {#- expect messages[0]['content'] to be a list of objects #}\n      {%- set first_user_message = messages[0]['content'][0]['text']|trim %}\n  {%- endif %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"You are an expert in using functions/tools when necessary. You are given a query and a set of possible functions. \"}}\n    {{- \"Based on the query, call one or more functions to achieve the purpose, if applicable.\\n\\n\"}}\n    {{- \"If no functions apply, do not call any. Make sure to use any parameters specified as required. \"}}\n    {{- \"If the given query lacks the parameters required by the function, \"}}\n    {{- \"point it out. If a function response is given after you call a function, use it if it answers the query. \"}}\n    {{- \"You should only output function calls in tool call sections.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument names and their values}. ' }}\n    {{- \"For number argument values, you do not need to wrap in quotes. If you use quotes, use double quotes. \"}}\n    {{- \"Do not use variables. Here is a list of the only functions you can invoke, in JSON format.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is iterable and message.content is not string %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n"
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.topPSampling",
                      "value": {
                        "checked": false,
                        "value": 1
                      }
                    },
                    {
                      "key": "llm.prediction.minPSampling",
                      "value": {
                        "checked": false,
                        "value": 0
                      }
                    },
                    {
                      "key": "llm.prediction.repeatPenalty",
                      "value": {
                        "checked": true,
                        "value": 1.1
                      }
                    },
                    {
                      "key": "llm.prediction.topKSampling",
                      "value": 100
                    },
                    {
                      "key": "llm.prediction.tools",
                      "value": {
                        "type": "none"
                      }
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 77.95528424841069,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 0.149,
                  "promptTokensCount": 101,
                  "predictedTokensCount": 81,
                  "totalTokensCount": 182
                }
              },
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1753378523464-0.17766867435196565",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "So what's up"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "meta-llama-3.1-8b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1753378551811-0.2702662445340277",
              "content": [
                {
                  "type": "text",
                  "text": "Not much, just waiting for you to ask me something or start a conversation. It's always more interesting when we talk about specific topics or questions.\n\nIf you're looking for ideas, I can suggest some conversation starters:\n\n- Hobbies or interests\n- Travel experiences\n- Books or movies you've enjoyed recently\n- Current events or news\n\nOr, if you'd rather not start with a specific topic, we could play a game or have some fun conversation. Just let me know what you're in the mood for!",
                  "fromDraftModel": false,
                  "tokensCount": 105
                }
              ],
              "genInfo": {
                "indexedModelIdentifier": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
                "identifier": "meta-llama-3.1-8b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.contextLength",
                      "value": 4096
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.toolCallStopStrings",
                      "value": [
                        "<|eom_id|>",
                        "<|eom|>"
                      ]
                    },
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- if messages[0]['content'] is string %}\n      {%- set first_user_message = messages[0]['content']|trim %}\n  {%- else %}\n      {#- expect messages[0]['content'] to be a list of objects #}\n      {%- set first_user_message = messages[0]['content'][0]['text']|trim %}\n  {%- endif %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"You are an expert in using functions/tools when necessary. You are given a query and a set of possible functions. \"}}\n    {{- \"Based on the query, call one or more functions to achieve the purpose, if applicable.\\n\\n\"}}\n    {{- \"If no functions apply, do not call any. Make sure to use any parameters specified as required. \"}}\n    {{- \"If the given query lacks the parameters required by the function, \"}}\n    {{- \"point it out. If a function response is given after you call a function, use it if it answers the query. \"}}\n    {{- \"You should only output function calls in tool call sections.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument names and their values}. ' }}\n    {{- \"For number argument values, you do not need to wrap in quotes. If you use quotes, use double quotes. \"}}\n    {{- \"Do not use variables. Here is a list of the only functions you can invoke, in JSON format.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is iterable and message.content is not string %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n"
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.topPSampling",
                      "value": {
                        "checked": false,
                        "value": 1
                      }
                    },
                    {
                      "key": "llm.prediction.minPSampling",
                      "value": {
                        "checked": false,
                        "value": 0
                      }
                    },
                    {
                      "key": "llm.prediction.repeatPenalty",
                      "value": {
                        "checked": true,
                        "value": 1.1
                      }
                    },
                    {
                      "key": "llm.prediction.topKSampling",
                      "value": 100
                    },
                    {
                      "key": "llm.prediction.tools",
                      "value": {
                        "type": "none"
                      }
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 77.34400443600846,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 0.112,
                  "promptTokensCount": 195,
                  "predictedTokensCount": 106,
                  "totalTokensCount": 301
                }
              },
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1753378553131-0.68966099077429",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "Hobbies"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "meta-llama-3.1-8b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1753378557347-0.06884470534937115",
              "content": [
                {
                  "type": "text",
                  "text": "Discussing hobbies can be a great way to learn more about each other's interests and tastes.\n\nWhat kind of hobbies do you enjoy? Are you into:\n\n- Outdoor activities like hiking, camping, or sports?\n- Creative pursuits such as painting, drawing, writing, or photography?\n- Music, playing an instrument, or singing?\n- Cooking or trying new recipes?\n- Reading, learning a new language, or playing games?\n\nLet me know, and I can provide more information or suggestions related to your hobbies!",
                  "fromDraftModel": false,
                  "tokensCount": 102
                }
              ],
              "genInfo": {
                "indexedModelIdentifier": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
                "identifier": "meta-llama-3.1-8b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.contextLength",
                      "value": 4096
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.toolCallStopStrings",
                      "value": [
                        "<|eom_id|>",
                        "<|eom|>"
                      ]
                    },
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- if messages[0]['content'] is string %}\n      {%- set first_user_message = messages[0]['content']|trim %}\n  {%- else %}\n      {#- expect messages[0]['content'] to be a list of objects #}\n      {%- set first_user_message = messages[0]['content'][0]['text']|trim %}\n  {%- endif %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"You are an expert in using functions/tools when necessary. You are given a query and a set of possible functions. \"}}\n    {{- \"Based on the query, call one or more functions to achieve the purpose, if applicable.\\n\\n\"}}\n    {{- \"If no functions apply, do not call any. Make sure to use any parameters specified as required. \"}}\n    {{- \"If the given query lacks the parameters required by the function, \"}}\n    {{- \"point it out. If a function response is given after you call a function, use it if it answers the query. \"}}\n    {{- \"You should only output function calls in tool call sections.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument names and their values}. ' }}\n    {{- \"For number argument values, you do not need to wrap in quotes. If you use quotes, use double quotes. \"}}\n    {{- \"Do not use variables. Here is a list of the only functions you can invoke, in JSON format.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is iterable and message.content is not string %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n"
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.topPSampling",
                      "value": {
                        "checked": false,
                        "value": 1
                      }
                    },
                    {
                      "key": "llm.prediction.minPSampling",
                      "value": {
                        "checked": false,
                        "value": 0
                      }
                    },
                    {
                      "key": "llm.prediction.repeatPenalty",
                      "value": {
                        "checked": true,
                        "value": 1.1
                      }
                    },
                    {
                      "key": "llm.prediction.topKSampling",
                      "value": 100
                    },
                    {
                      "key": "llm.prediction.tools",
                      "value": {
                        "type": "none"
                      }
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 76.69477776240996,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 0.121,
                  "promptTokensCount": 312,
                  "predictedTokensCount": 103,
                  "totalTokensCount": 415
                }
              },
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1753378558652-0.6633596909683371",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "A good goulash recipe"
            }
          ]
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "senderInfo": {
            "senderName": "meta-llama-3.1-8b-instruct"
          },
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1753378666548-0.9498232741260648",
              "content": [
                {
                  "type": "text",
                  "text": "A delicious topic indeed. Goulash is a classic dish that's perfect for any time of the year, and I'd be happy to share a simple yet flavorful recipe with you.\n\nHere's one that yields a hearty and savory goulash:\n\n**Classic Beef Goulash Recipe**\n\nIngredients:\n\n- 2 tablespoons olive oil\n- 1 large onion, chopped\n- 3 cloves garlic, minced\n- 2 pounds beef (such as chuck or brisket), cut into 1-inch cubes\n- 2 cups beef broth\n- 1 cup diced tomatoes (canned or fresh)\n- 2 teaspoons paprika\n- 1 teaspoon caraway seeds\n- Salt and pepper, to taste\n- Optional: noodles or bread for serving\n\nInstructions:\n\n1. Heat the oil in a large Dutch oven over medium heat.\n2. Add the onion and garlic; cook until softened, about 5 minutes.\n3. Add the beef; cook until browned on all sides, about 5-7 minutes.\n4. Add the broth, tomatoes, paprika, and caraway seeds. Stir to combine.\n5. Bring the mixture to a boil; reduce heat to low and simmer for 1-2 hours or until the beef is tender.\n6. Season with salt and pepper to taste.\n7. Serve over noodles or with crusty bread, if desired.\n\n**Variations:**\n\n- Use ground beef instead of cubed beef for a heartier, faster-cooking version.\n- Add other vegetables like bell peppers, mushrooms, or carrots to the pot for added flavor and nutrition.\n- For a vegetarian option, replace the beef with chickpeas or other plant-based protein sources.\n\n**Tips:**\n\n- Let the goulash simmer for a couple of hours to allow the flavors to meld together and the beef to become tender.\n- If you prefer a thicker goulash, mix in 1-2 tablespoons flour with the broth before adding it to the pot.\n- Experiment with different spice combinations or add a splash of vinegar for added depth.\n\nEnjoy your delicious homemade goulash!\n\nHow does this recipe sound? Would you like any variations or substitutions?",
                  "fromDraftModel": false,
                  "tokensCount": 441
                }
              ],
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true,
              "genInfo": {
                "indexedModelIdentifier": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
                "identifier": "meta-llama-3.1-8b-instruct",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.contextLength",
                      "value": 4096
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.toolCallStopStrings",
                      "value": [
                        "<|eom_id|>",
                        "<|eom|>"
                      ]
                    },
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- if messages[0]['content'] is string %}\n      {%- set first_user_message = messages[0]['content']|trim %}\n  {%- else %}\n      {#- expect messages[0]['content'] to be a list of objects #}\n      {%- set first_user_message = messages[0]['content'][0]['text']|trim %}\n  {%- endif %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"You are an expert in using functions/tools when necessary. You are given a query and a set of possible functions. \"}}\n    {{- \"Based on the query, call one or more functions to achieve the purpose, if applicable.\\n\\n\"}}\n    {{- \"If no functions apply, do not call any. Make sure to use any parameters specified as required. \"}}\n    {{- \"If the given query lacks the parameters required by the function, \"}}\n    {{- \"point it out. If a function response is given after you call a function, use it if it answers the query. \"}}\n    {{- \"You should only output function calls in tool call sections.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument names and their values}. ' }}\n    {{- \"For number argument values, you do not need to wrap in quotes. If you use quotes, use double quotes. \"}}\n    {{- \"Do not use variables. Here is a list of the only functions you can invoke, in JSON format.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is iterable and message.content is not string %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n"
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.topPSampling",
                      "value": {
                        "checked": false,
                        "value": 1
                      }
                    },
                    {
                      "key": "llm.prediction.minPSampling",
                      "value": {
                        "checked": false,
                        "value": 0
                      }
                    },
                    {
                      "key": "llm.prediction.repeatPenalty",
                      "value": {
                        "checked": true,
                        "value": 1.1
                      }
                    },
                    {
                      "key": "llm.prediction.topKSampling",
                      "value": 100
                    },
                    {
                      "key": "llm.prediction.tools",
                      "value": {
                        "type": "none"
                      }
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 75.06904398893121,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 0.121,
                  "promptTokensCount": 430,
                  "predictedTokensCount": 442,
                  "totalTokensCount": 872
                }
              }
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1753378672411-0.10339712154171998",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ]
        }
      ],
      "currentlySelected": 0
    }
  ],
  "usePerChatPredictionConfig": true,
  "perChatPredictionConfig": {
    "fields": []
  },
  "clientInput": "",
  "clientInputFiles": [],
  "userFilesSizeBytes": 0,
  "lastUsedModel": {
    "indexedModelIdentifier": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
    "identifier": "meta-llama-3.1-8b-instruct",
    "instanceLoadTimeConfig": {
      "fields": []
    },
    "instanceOperationTimeConfig": {
      "fields": []
    }
  },
  "notes": [],
  "plugins": [],
  "pluginConfigs": {},
  "disabledPluginTools": [],
  "looseFiles": []
}